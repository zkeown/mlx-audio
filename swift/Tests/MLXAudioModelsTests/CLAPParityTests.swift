// CLAPParityTests.swift
// Parity tests comparing Swift CLAP implementation against Python.
//
// These tests load fixtures generated by:
//   python tests/generate_clap_fixtures.py --output-dir swift/Tests/Fixtures/CLAP
//
// Run from the python/ directory to generate fixtures before running these tests.

import XCTest
@testable import MLXAudioModels
import MLX
import MLXNN

/// Parity tests for CLAP Swift implementation.
///
/// These tests compare Swift outputs against Python-generated fixtures
/// to ensure numerical equivalence within tolerance.
final class CLAPParityTests: XCTestCase {

    // MARK: - Test Configuration

    /// Tolerance for individual layer tests
    static let layerTolerance: Float = 1e-5

    /// Tolerance for multi-layer chains (accumulated error)
    static let chainTolerance: Float = 1e-4

    /// Tolerance for full model tests
    static let modelTolerance: Float = 1e-3

    /// Minimum cosine similarity for embedding comparison
    static let cosineSimilarityThreshold: Float = 0.999

    /// Path to fixtures directory
    static var fixturesPath: URL {
        // Try environment variable first
        if let envPath = ProcessInfo.processInfo.environment["CLAP_FIXTURES_PATH"] {
            return URL(fileURLWithPath: envPath)
        }

        // Common fixture locations to check
        let possiblePaths = [
            // Relative to source file
            URL(fileURLWithPath: #filePath)
                .deletingLastPathComponent()  // CLAPParityTests.swift
                .deletingLastPathComponent()  // MLXAudioModelsTests
                .deletingLastPathComponent()  // Tests
                .appendingPathComponent("Fixtures")
                .appendingPathComponent("CLAP"),

            // Current working directory patterns
            URL(fileURLWithPath: FileManager.default.currentDirectoryPath)
                .appendingPathComponent("Tests")
                .appendingPathComponent("Fixtures")
                .appendingPathComponent("CLAP"),

            URL(fileURLWithPath: FileManager.default.currentDirectoryPath)
                .appendingPathComponent("swift")
                .appendingPathComponent("Tests")
                .appendingPathComponent("Fixtures")
                .appendingPathComponent("CLAP"),

            // Common development paths
            URL(fileURLWithPath: NSHomeDirectory())
                .appendingPathComponent("Code/mlx-audio/swift/Tests/Fixtures/CLAP"),
        ]

        for path in possiblePaths {
            if FileManager.default.fileExists(atPath: path.path) {
                return path
            }
        }

        // Default fallback
        return possiblePaths[0]
    }

    /// Check if fixtures are available
    static var fixturesAvailable: Bool {
        FileManager.default.fileExists(atPath: fixturesPath.path)
    }

    // MARK: - Helper Methods

    /// Load arrays from a safetensors fixture file.
    func loadFixture(_ name: String) throws -> [String: MLXArray] {
        let url = Self.fixturesPath.appendingPathComponent("\(name).safetensors")
        guard FileManager.default.fileExists(atPath: url.path) else {
            throw CLAPParityTestError.fixtureNotFound(name)
        }
        return try MLX.loadArrays(url: url)
    }

    /// Load JSON config file.
    func loadConfig(_ name: String) throws -> [String: Any] {
        let url = Self.fixturesPath.appendingPathComponent("\(name).json")
        let data = try Data(contentsOf: url)
        guard let json = try JSONSerialization.jsonObject(with: data) as? [String: Any] else {
            throw CLAPParityTestError.invalidConfig(name)
        }
        return json
    }

    /// Calculate maximum absolute difference between two arrays.
    func maxAbsDiff(_ a: MLXArray, _ b: MLXArray) -> Float {
        let diff = abs(a - b)
        return diff.max().item(Float.self)
    }

    /// Calculate mean absolute difference between two arrays.
    func meanAbsDiff(_ a: MLXArray, _ b: MLXArray) -> Float {
        let diff = abs(a - b)
        return diff.mean().item(Float.self)
    }

    /// Calculate cosine similarity between two arrays.
    func cosineSimilarity(_ a: MLXArray, _ b: MLXArray) -> Float {
        let aFlat = a.reshaped([-1])
        let bFlat = b.reshaped([-1])
        let dot = sum(aFlat * bFlat)
        let normA = sqrt(sum(aFlat * aFlat))
        let normB = sqrt(sum(bFlat * bFlat))
        return (dot / (normA * normB)).item(Float.self)
    }

    /// Assert arrays are equal within tolerance.
    func assertArraysEqual(
        _ actual: MLXArray,
        _ expected: MLXArray,
        tolerance: Float,
        message: String = "",
        file: StaticString = #file,
        line: UInt = #line
    ) {
        let diff = maxAbsDiff(actual, expected)
        XCTAssertLessThan(
            diff,
            tolerance,
            "Arrays differ by \(diff), exceeds tolerance \(tolerance). \(message)",
            file: file,
            line: line
        )
    }

    /// Assert embeddings are similar using cosine similarity.
    func assertEmbeddingsSimilar(
        _ actual: MLXArray,
        _ expected: MLXArray,
        threshold: Float = 0.999,
        message: String = "",
        file: StaticString = #file,
        line: UInt = #line
    ) {
        let similarity = cosineSimilarity(actual, expected)
        XCTAssertGreaterThan(
            similarity,
            threshold,
            "Cosine similarity \(similarity) below threshold \(threshold). \(message)",
            file: file,
            line: line
        )
    }

    /// Skip test if fixtures not available.
    func skipIfNoFixtures(file: StaticString = #file, line: UInt = #line) throws {
        try XCTSkipUnless(
            Self.fixturesAvailable,
            "Fixtures not found at \(Self.fixturesPath.path). Run: python tests/generate_clap_fixtures.py",
            file: file,
            line: line
        )
    }

    // MARK: - PatchEmbed Parity Tests

    func testPatchEmbedParity() throws {
        try skipIfNoFixtures()

        let fixtures = try loadFixture("patch_embed")
        let weights = try loadFixture("patch_embed_weights")

        let input = fixtures["input"]!
        let expectedOutput = fixtures["output"]!

        // Create PatchEmbed with same config
        let patchEmbed = PatchEmbed(
            patchSize: 4,
            patchStride: (4, 4),
            inChans: 1,
            embedDim: 96,
            flatten: true,
            enableFusion: false
        )
        try patchEmbed.update(parameters: ModuleParameters.unflattened(weights), verify: .noUnusedKeys)

        // Run forward pass
        let output = patchEmbed(input)

        // Compare
        assertArraysEqual(
            output,
            expectedOutput,
            tolerance: Self.layerTolerance,
            message: "PatchEmbed output mismatch"
        )
    }

    // MARK: - Swin Block Parity Tests

    func testSwinBlockParity() throws {
        try skipIfNoFixtures()

        let fixtures = try loadFixture("swin_block")
        let weights = try loadFixture("swin_block_weights")

        let input = fixtures["input"]!
        let expectedOutput = fixtures["output"]!

        // Create BasicLayer
        let basicLayer = BasicLayer(
            dim: 96,
            depth: 2,
            numHeads: 4,
            windowSize: 8,
            mlpRatio: 4.0,
            qkvBias: true,
            drop: 0.0,
            attnDrop: 0.0,
            dropPath: [0.0, 0.0],  // Array of drop path rates per block
            downsampleEnabled: false
        )
        try basicLayer.update(parameters: ModuleParameters.unflattened(weights))

        // Run forward pass - BasicLayer returns (output, H, W) tuple
        // Get H, W from fixtures or compute from input shape
        let H = fixtures["height"]?.item(Int.self) ?? 64
        let W = fixtures["width"]?.item(Int.self) ?? 64
        let (output, _, _) = basicLayer(input, H: H, W: W)

        // Compare with chain tolerance (multiple blocks)
        assertArraysEqual(
            output,
            expectedOutput,
            tolerance: Self.chainTolerance,
            message: "SwinBlock output mismatch"
        )
    }

    // MARK: - HTSAT Encoder Parity Tests

    func testHTSATEncoderParity() throws {
        try skipIfNoFixtures()

        let fixtures = try loadFixture("htsat_encoder")
        let weights = try loadFixture("htsat_encoder_weights")
        let configDict = try loadConfig("htsat_config")

        let input = fixtures["input"]!
        let expectedOutput = fixtures["output"]!

        // Create HTSAT with small config
        let config = CLAPAudioConfig(
            nMels: configDict["n_mels"] as? Int ?? 64,
            patchSize: configDict["patch_size"] as? Int ?? 4,
            patchStride: {
                if let arr = configDict["patch_stride"] as? [Int], arr.count == 2 {
                    return (arr[0], arr[1])
                }
                return (4, 4)
            }(),
            embedDim: configDict["embed_dim"] as? Int ?? 48,
            depths: (configDict["depths"] as? [Int]) ?? [1, 1, 2, 1],
            numHeads: (configDict["num_heads"] as? [Int]) ?? [2, 4, 8, 16],
            windowSize: configDict["window_size"] as? Int ?? 4,
            hiddenSize: configDict["hidden_size"] as? Int ?? 384,
            enableFusion: configDict["enable_fusion"] as? Bool ?? false,
            specSize: configDict["spec_size"] as? Int ?? 256
        )

        let htsat = HTSAT(config: config)
        try htsat.update(parameters: ModuleParameters.unflattened(weights), verify: .noUnusedKeys)

        // Run forward pass
        let output = htsat(input)

        // Compare with chain tolerance
        assertArraysEqual(
            output,
            expectedOutput,
            tolerance: Self.chainTolerance,
            message: "HTSAT encoder output mismatch"
        )
    }

    // MARK: - RoBERTa Encoder Parity Tests

    func testRobertaEncoderParity() throws {
        try skipIfNoFixtures()

        let fixtures = try loadFixture("roberta_encoder")
        let weights = try loadFixture("roberta_encoder_weights")
        let configDict = try loadConfig("roberta_config")

        let inputIds = fixtures["input_ids"]!
        let attentionMask = fixtures["attention_mask"]!
        let expectedOutput = fixtures["output"]!

        // Create text encoder with small config
        let config = CLAPTextConfig(
            vocabSize: configDict["vocab_size"] as? Int ?? 1000,
            hiddenSize: configDict["hidden_size"] as? Int ?? 256,
            numHiddenLayers: configDict["num_hidden_layers"] as? Int ?? 2,
            numAttentionHeads: configDict["num_attention_heads"] as? Int ?? 4,
            intermediateSize: configDict["intermediate_size"] as? Int ?? 512
        )
        let projectionDim = configDict["projection_dim"] as? Int ?? 256

        let textEncoder = CLAPTextEncoder(config: config, projectionDim: projectionDim)
        try textEncoder.update(parameters: ModuleParameters.unflattened(weights), verify: .noUnusedKeys)

        // Run forward pass
        let output = textEncoder(inputIds, attentionMask: attentionMask, normalize: true)

        // Compare
        assertArraysEqual(
            output,
            expectedOutput,
            tolerance: Self.chainTolerance,
            message: "RoBERTa encoder output mismatch"
        )
    }

    // MARK: - Projection Head Parity Tests

    func testAudioProjectionParity() throws {
        try skipIfNoFixtures()

        let fixtures = try loadFixture("audio_projection")
        let weights = try loadFixture("audio_projection_weights")

        let input = fixtures["input"]!
        let expectedOutput = fixtures["output"]!

        // Create projection
        let projection = CLAPProjection(inDim: 384, outDim: 256)
        try projection.update(parameters: ModuleParameters.unflattened(weights), verify: .noUnusedKeys)

        // Run forward pass
        let output = projection(input)

        // Compare
        assertArraysEqual(
            output,
            expectedOutput,
            tolerance: Self.layerTolerance,
            message: "Audio projection output mismatch"
        )
    }

    // MARK: - Small Model Parity Tests

    func testSmallModelParity() throws {
        try skipIfNoFixtures()

        // Check if small model fixtures exist
        let smallModelPath = Self.fixturesPath.appendingPathComponent("small_model.safetensors")
        try XCTSkipUnless(
            FileManager.default.fileExists(atPath: smallModelPath.path),
            "Small model fixtures not found"
        )

        let fixtures = try loadFixture("small_model")
        let weights = try loadFixture("small_model_weights")

        // Load config
        let configURL = Self.fixturesPath.appendingPathComponent("small_model_config.json")
        let configData = try Data(contentsOf: configURL)
        let config = try JSONDecoder().decode(CLAPConfig.self, from: configData)

        let audioInput = fixtures["audio_input"]!
        let inputIds = fixtures["input_ids"]!
        let attentionMask = fixtures["attention_mask"]!
        let expectedAudioEmbeds = fixtures["audio_embeds"]!
        let expectedTextEmbeds = fixtures["text_embeds"]!
        let expectedLogits = fixtures["logits_per_audio"]!

        // Create model
        let model = CLAPModel(config: config)
        try model.update(parameters: ModuleParameters.unflattened(weights), verify: .noUnusedKeys)

        // Forward pass
        let result = try model(audio: audioInput, inputIds: inputIds, attentionMask: attentionMask)

        // Compare audio embeddings
        assertArraysEqual(
            result.audioEmbeds!,
            expectedAudioEmbeds,
            tolerance: Self.modelTolerance,
            message: "Audio embeddings mismatch"
        )

        // Compare text embeddings
        assertArraysEqual(
            result.textEmbeds!,
            expectedTextEmbeds,
            tolerance: Self.modelTolerance,
            message: "Text embeddings mismatch"
        )

        // Compare logits
        assertArraysEqual(
            result.logitsPerAudio!,
            expectedLogits,
            tolerance: Self.modelTolerance,
            message: "Logits mismatch"
        )

        // Also verify embeddings are similar using cosine similarity
        assertEmbeddingsSimilar(
            result.audioEmbeds!,
            expectedAudioEmbeds,
            threshold: Self.cosineSimilarityThreshold,
            message: "Audio embeddings cosine similarity too low"
        )
    }

    // MARK: - Full Model Parity Tests

    func testFullModelParity() throws {
        try skipIfNoFixtures()

        // Check if full model fixtures exist
        let fullModelPath = Self.fixturesPath.appendingPathComponent("full_model.safetensors")
        try XCTSkipUnless(
            FileManager.default.fileExists(atPath: fullModelPath.path),
            "Full model fixtures not found"
        )

        let fixtures = try loadFixture("full_model")

        // Check if we have weights (only for random init, not pretrained)
        let weightsPath = Self.fixturesPath.appendingPathComponent("full_model_weights.safetensors")
        let hasWeights = FileManager.default.fileExists(atPath: weightsPath.path)

        // Load config
        let configURL = Self.fixturesPath.appendingPathComponent("config.json")
        let configData = try Data(contentsOf: configURL)
        let config = try JSONDecoder().decode(CLAPConfig.self, from: configData)

        let audioInput = fixtures["audio_input"]!
        let inputIds = fixtures["input_ids"]!
        let attentionMask = fixtures["attention_mask"]!
        let expectedAudioEmbeds = fixtures["audio_embeds"]!
        let expectedTextEmbeds = fixtures["text_embeds"]!

        // Create model
        let model = CLAPModel(config: config)

        if hasWeights {
            let weights = try loadFixture("full_model_weights")
            try model.update(parameters: ModuleParameters.unflattened(weights), verify: .noUnusedKeys)

            // Forward pass
            let result = try model(audio: audioInput, inputIds: inputIds, attentionMask: attentionMask)

            // Compare embeddings
            assertArraysEqual(
                result.audioEmbeds!,
                expectedAudioEmbeds,
                tolerance: Self.modelTolerance,
                message: "Full model audio embeddings mismatch"
            )

            assertArraysEqual(
                result.textEmbeds!,
                expectedTextEmbeds,
                tolerance: Self.modelTolerance,
                message: "Full model text embeddings mismatch"
            )
        } else {
            // For pretrained models, just verify shapes match
            let result = try model(audio: audioInput, inputIds: inputIds, attentionMask: attentionMask)

            XCTAssertEqual(
                result.audioEmbeds!.shape,
                expectedAudioEmbeds.shape,
                "Audio embedding shape mismatch"
            )
            XCTAssertEqual(
                result.textEmbeds!.shape,
                expectedTextEmbeds.shape,
                "Text embedding shape mismatch"
            )
        }
    }

    // MARK: - Shape Consistency Tests

    func testOutputShapeConsistency() throws {
        try skipIfNoFixtures()

        // Check if small model fixtures exist
        let smallModelPath = Self.fixturesPath.appendingPathComponent("small_model.safetensors")
        try XCTSkipUnless(
            FileManager.default.fileExists(atPath: smallModelPath.path),
            "Small model fixtures not found"
        )

        let fixtures = try loadFixture("small_model")

        let audioInput = fixtures["audio_input"]!
        let inputIds = fixtures["input_ids"]!
        let attentionMask = fixtures["attention_mask"]!
        let expectedAudioEmbeds = fixtures["audio_embeds"]!
        let expectedTextEmbeds = fixtures["text_embeds"]!
        let expectedLogits = fixtures["logits_per_audio"]!

        // Load config
        let configURL = Self.fixturesPath.appendingPathComponent("small_model_config.json")
        let configData = try Data(contentsOf: configURL)
        let config = try JSONDecoder().decode(CLAPConfig.self, from: configData)

        // Create model (random weights)
        let model = CLAPModel(config: config)

        // Forward pass
        let result = try model(audio: audioInput, inputIds: inputIds, attentionMask: attentionMask)

        // Verify shapes
        XCTAssertEqual(
            result.audioEmbeds!.shape,
            expectedAudioEmbeds.shape,
            "Audio embedding shape: Swift \(result.audioEmbeds!.shape) vs Python \(expectedAudioEmbeds.shape)"
        )
        XCTAssertEqual(
            result.textEmbeds!.shape,
            expectedTextEmbeds.shape,
            "Text embedding shape: Swift \(result.textEmbeds!.shape) vs Python \(expectedTextEmbeds.shape)"
        )
        XCTAssertEqual(
            result.logitsPerAudio!.shape,
            expectedLogits.shape,
            "Logits shape: Swift \(result.logitsPerAudio!.shape) vs Python \(expectedLogits.shape)"
        )
    }
}

// MARK: - Errors

enum CLAPParityTestError: Error, LocalizedError {
    case fixtureNotFound(String)
    case invalidConfig(String)

    var errorDescription: String? {
        switch self {
        case .fixtureNotFound(let name):
            return "Fixture not found: \(name).safetensors"
        case .invalidConfig(let name):
            return "Invalid config file: \(name).json"
        }
    }
}

// MARK: - Performance Tests

extension CLAPParityTests {

    /// Benchmark audio encoding performance.
    func testAudioEncodingPerformance() throws {
        // Use small config for benchmark
        let audioConfig = CLAPAudioConfig(
            nMels: 64,
            patchSize: 4,
            embedDim: 48,
            depths: [1, 1, 1, 1],
            numHeads: [2, 4, 8, 8],
            windowSize: 4,
            hiddenSize: 192,
            enableFusion: false,
            specSize: 128
        )

        let config = CLAPConfig(audio: audioConfig)
        let model = CLAPModel(config: config)

        // Generate input
        let audioInput = MLXRandom.normal([1, 1, 64, 128])

        // Warmup
        _ = try? model.encodeAudio(audioInput)
        eval()

        measure {
            _ = try? model.encodeAudio(audioInput)
            eval()
        }
    }

    /// Benchmark text encoding performance.
    func testTextEncodingPerformance() throws {
        let textConfig = CLAPTextConfig(
            vocabSize: 1000,
            hiddenSize: 192,
            numHiddenLayers: 2,
            numAttentionHeads: 4,
            intermediateSize: 384
        )

        let config = CLAPConfig(text: textConfig, projectionDim: 128)
        let model = CLAPModel(config: config)

        // Generate input
        let inputIds = MLXRandom.randInt(low: 4, high: 1000, [1, 32])
        let attentionMask = ones([1, 32], type: Int32.self)

        // Warmup
        _ = try model.encodeText(inputIds, attentionMask: attentionMask)
        eval()

        measure {
            _ = try? model.encodeText(inputIds, attentionMask: attentionMask)
            eval()
        }
    }
}
