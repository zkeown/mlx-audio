name: Parity Tests

on:
  pull_request:
    branches: [main]
    paths:
      - "python/mlx_audio/models/**"
      - "swift/Sources/MLXAudioModels/**"
      - "python/tests/**/generate_*.py"
      - "python/tests/parity/**"
      - "python/tests/benchmarks/**"
      - "swift/Tests/**/*ParityTests.swift"
      - "swift/Tests/**/*QualityTests.swift"
  schedule:
    - cron: "0 2 * * 0"  # Sundays at 2am UTC
  workflow_dispatch:
    inputs:
      models:
        description: "Models to test (comma-separated, or 'all')"
        required: false
        default: "all"
      run_benchmarks:
        description: "Run quality benchmarks"
        required: false
        type: boolean
        default: false

jobs:
  # Job 1: Run Python parity tests (against reference implementations)
  python-parity:
    name: Python Parity Tests
    runs-on: macos-latest
    steps:
      - uses: actions/checkout@v6

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('python/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          cd python
          pip install -e ".[dev,test]"

      - name: Run Python parity tests
        run: |
          cd python
          python -m pytest tests -m parity -v --tb=short

  # Job 2: Generate fixtures and run Swift parity tests
  swift-parity:
    name: Swift Parity Tests
    runs-on: macos-latest
    steps:
      - uses: actions/checkout@v6

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('python/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python dependencies
        run: |
          cd python
          pip install -e ".[dev]"

      - name: Generate parity fixtures
        run: |
          cd python
          python tests/parity/generate_references.py \
            --model ${{ github.event.inputs.models || 'all' }} \
            --output-dir ../swift/Tests/Fixtures \
            --layers-only \
            --verbose

      - name: List generated fixtures
        run: |
          echo "Generated fixtures:"
          find swift/Tests/Fixtures -type f -name "*.safetensors" -o -name "*.json" | head -50

      - name: Build Swift package
        run: |
          cd swift
          swift build

      - name: Run Swift parity tests
        env:
          HTDEMUCS_FIXTURES_PATH: ${{ github.workspace }}/swift/Tests/Fixtures/HTDemucs
          CLAP_FIXTURES_PATH: ${{ github.workspace }}/swift/Tests/Fixtures/CLAP
          MUSICGEN_FIXTURES_PATH: ${{ github.workspace }}/swift/Tests/Fixtures/MusicGen
          ENCODEC_FIXTURES_PATH: ${{ github.workspace }}/swift/Tests/Fixtures/EnCodec
          WHISPER_FIXTURES_PATH: ${{ github.workspace }}/swift/Tests/Fixtures/Whisper
        run: |
          cd swift
          swift test --filter ParityTests 2>&1 | tee test-output.txt

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: swift-parity-test-results
          path: swift/test-output.txt
          retention-days: 7

      - name: Upload fixtures (for debugging)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: parity-fixtures
          path: swift/Tests/Fixtures/
          retention-days: 3

  # Job 3: Quality benchmarks (optional, triggered manually or on schedule)
  quality-benchmarks:
    name: Quality Benchmarks
    runs-on: macos-latest
    if: github.event_name == 'schedule' || github.event.inputs.run_benchmarks == 'true'
    steps:
      - uses: actions/checkout@v6

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-benchmarks-${{ hashFiles('python/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          cd python
          pip install -e ".[dev,test]"
          pip install mir_eval jiwer

      - name: Run quality benchmarks
        run: |
          cd python
          python -m pytest tests/benchmarks/ -v --tb=short -x 2>&1 | tee benchmark-output.txt
        continue-on-error: true

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quality-benchmark-results
          path: python/benchmark-output.txt
          retention-days: 30

  # Job 4: Summary
  summary:
    name: Parity Summary
    runs-on: ubuntu-latest
    needs: [python-parity, swift-parity]
    if: always()
    steps:
      - name: Check results
        run: |
          echo "## Parity Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.python-parity.result }}" == "success" ]; then
            echo "✅ Python parity tests passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Python parity tests failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.swift-parity.result }}" == "success" ]; then
            echo "✅ Swift parity tests passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ Swift parity tests failed" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "${{ needs.python-parity.result }}" != "success" ] || \
             [ "${{ needs.swift-parity.result }}" != "success" ]; then
            echo ""
            echo "### Summary"
            echo "Some parity tests failed. Please check the individual job logs for details."
            exit 1
          fi

          echo ""
          echo "### Summary"
          echo "All parity tests passed! Swift and Python implementations are numerically equivalent."
